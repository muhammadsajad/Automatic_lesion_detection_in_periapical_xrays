{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1RfB4X9gFPHMf45_LGlpTdWp9_XD-5h1r",
      "authorship_tag": "ABX9TyMArvk9sQaAZil0uOC/mcA7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/muhammadsajad/Automatic_lesion_detection_using_periapical_xrays/blob/main/Method_A.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Method A**\n",
        "\n",
        "\n",
        "1.   Feature extraction using vgg16\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "T50_miwS_w5Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import cv2\n",
        "import random\n",
        "from shutil import copyfile\n",
        "\n",
        "\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
        "# from keras.layers.normalization import BatchNormalization\n",
        "import os\n",
        "import seaborn as sns\n",
        "from keras.applications.vgg16 import VGG16"
      ],
      "metadata": {
        "id": "shbFUUi2_1Pd"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Give the path of kaggle.jason file in order to download data directly from kaggle.\n",
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR']='/content'"
      ],
      "metadata": {
        "id": "SDFmLq_Ls2bq"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This is the kaggle api of data set.\n",
        "!kaggle datasets download -d muhammadsajad/periapical-xrays"
      ],
      "metadata": {
        "id": "ClZG16dRDJkC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0705edbd-46de-4294-fde9-f033569de91a"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /content/kaggle.json'\n",
            "Downloading periapical-xrays.zip to /content\n",
            " 96% 148M/153M [00:03<00:00, 36.8MB/s]\n",
            "100% 153M/153M [00:03<00:00, 47.4MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip the data set\n",
        "!unzip \\*.zip && rm *.zip"
      ],
      "metadata": {
        "id": "r10A4VzvsqHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display total number of images present in each category\n",
        "source_path = '/content/Periapical_Xrays'\n",
        "\n",
        "source_path_Primary_Endo_with_Secondary_Perio = os.path.join(source_path, 'Primary Endo with Secondary Perio')\n",
        "source_path_Primary_Endodontic_Lesion = os.path.join(source_path, 'Primary Endodontic Lesion')\n",
        "source_path_Primary_Perio_with_Secondary_Endo = os.path.join(source_path, 'Primary Perio with Secondary Endo')\n",
        "source_path_Primary_Periodontal_Lesion = os.path.join(source_path, 'Primary Periodontal Lesion')\n",
        "source_path_True_Combined_Lesions = os.path.join(source_path, 'True Combined Lesions')\n",
        "\n",
        "# # Deletes all non-image files (there are two .db files bundled into the dataset)\n",
        "# !find /tmp/PetImages/ -type f ! -name \"*.jpg\" -exec rm {} +\n",
        "\n",
        "# os.listdir returns a list containing all files under the given path\n",
        "print(f\"There are {len(os.listdir(source_path_Primary_Endo_with_Secondary_Perio))} images of Primary Endo with Secondary Perio.\")\n",
        "print(f\"There are {len(os.listdir(source_path_Primary_Endodontic_Lesion))} images of Primary Endodontic Lesion.\")\n",
        "print(f\"There are {len(os.listdir(source_path_Primary_Perio_with_Secondary_Endo))} images of Primary Perio with Secondary Endo.\")\n",
        "print(f\"There are {len(os.listdir(source_path_Primary_Periodontal_Lesion))} images of Primary Periodontal Lesion.\")\n",
        "print(f\"There are {len(os.listdir(source_path_True_Combined_Lesions))} images of True Combined Lesions.\")"
      ],
      "metadata": {
        "id": "AFv4dEAjBF1z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bfb3170-acab-4c62-8df3-79ce55ca82e4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 122 images of Primary Endo with Secondary Perio.\n",
            "There are 124 images of Primary Endodontic Lesion.\n",
            "There are 39 images of Primary Perio with Secondary Endo.\n",
            "There are 118 images of Primary Periodontal Lesion.\n",
            "There are 131 images of True Combined Lesions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Now we create two trianing and validation directories and in that directories creating subdirectories for each catogory/class."
      ],
      "metadata": {
        "id": "FnL2Cxa3LjtS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "# Define root directory\n",
        "root_dir = '/content/Xrays'\n",
        "\n",
        "# Empty directory to prevent FileExistsError is the function is run several times\n",
        "if os.path.exists(root_dir):\n",
        "  shutil.rmtree(root_dir)\n",
        "\n",
        "# create_train_val_dirs\n",
        "def create_train_val_dirs(root_path):\n",
        "  \"\"\"\n",
        "  Creates directories for the train and test sets\n",
        "\n",
        "  Args:\n",
        "    root_path (string) - the base directory path to create subdirectories from\n",
        "\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "  #This for creating training subdirectory\n",
        "  parent_dir = root_path + \"/training\"\n",
        "  path=os.path.join(parent_dir,'Primary Endo with Secondary Perio')\n",
        "  os.makedirs(path)\n",
        "  path=os.path.join(parent_dir,'Primary Endodontic Lesion')\n",
        "  os.makedirs(path)\n",
        "  path=os.path.join(parent_dir,'Primary Perio with Secondary Endo')\n",
        "  os.makedirs(path)\n",
        "  path=os.path.join(parent_dir,'Primary Periodontal Lesion')\n",
        "  os.makedirs(path)\n",
        "  path=os.path.join(parent_dir,'True Combined Lesions')\n",
        "  os.makedirs(path)\n",
        "\n",
        "  # This for creating validation subdirectory\n",
        "  parent_dir=root_path + \"/validation\"\n",
        "  path=os.path.join(parent_dir,'Primary Endo with Secondary Perio')\n",
        "  os.makedirs(path)\n",
        "  path=os.path.join(parent_dir,'Primary Endodontic Lesion')\n",
        "  os.makedirs(path)\n",
        "  path=os.path.join(parent_dir,'Primary Perio with Secondary Endo')\n",
        "  os.makedirs(path)\n",
        "  path=os.path.join(parent_dir,'Primary Periodontal Lesion')\n",
        "  os.makedirs(path)\n",
        "  path=os.path.join(parent_dir,'True Combined Lesions')\n",
        "  os.makedirs(path)\n",
        "\n",
        "\n",
        "\n",
        "  ### END CODE HERE\n",
        "\n",
        "\n",
        "try:\n",
        "  create_train_val_dirs(root_path=root_dir)\n",
        "except FileExistsError:\n",
        "  print(\"You should not be seeing this since the upper directory is removed beforehand\")"
      ],
      "metadata": {
        "id": "cE4n0uBuMAxi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for rootdir, dirs, files in os.walk(root_dir):\n",
        "    for subdir in dirs:\n",
        "        print(os.path.join(rootdir, subdir))"
      ],
      "metadata": {
        "id": "xpuiYYJFNsQD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split_data\n",
        "def split_data(SOURCE_DIR, TRAINING_DIR, VALIDATION_DIR, SPLIT_SIZE):\n",
        "  \"\"\"\n",
        "  Splits the data into train and test sets\n",
        "\n",
        "  Args:\n",
        "    SOURCE_DIR (string): directory path containing the images\n",
        "    TRAINING_DIR (string): directory path to be used for training\n",
        "    VALIDATION_DIR (string): directory path to be used for validation\n",
        "    SPLIT_SIZE (float): proportion of the dataset to be used for training\n",
        "\n",
        "  Returns:\n",
        "    None\n",
        "  \"\"\"\n",
        "\n",
        "  shuffle_list=random.sample(os.listdir(SOURCE_DIR),len(os.listdir(SOURCE_DIR)))\n",
        "\n",
        "  training_number=int(len(shuffle_list)*SPLIT_SIZE)\n",
        "\n",
        "  i=0\n",
        "  target=TRAINING_DIR\n",
        "\n",
        "  for item in shuffle_list:\n",
        "    item_source=os.path.join(SOURCE_DIR,item)\n",
        "    if os.path.getsize(item_source)==0:\n",
        "      print(f'{item}is zero length, so ignoring.')\n",
        "    else:\n",
        "      copyfile(item_source,os.path.join(target,item))\n",
        "      i+=1\n",
        "\n",
        "    if i==training_number:\n",
        "      target=VALIDATION_DIR\n"
      ],
      "metadata": {
        "id": "uOc-KsRYOn0w"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Define paths\n",
        "Pr_En_wi_Se_Pe_SOURCE_DIR = \"/content/Periapical_Xrays/Primary Endo with Secondary Perio\"\n",
        "Pr_En_Le_SOURCE_DIR = \"/content/Periapical_Xrays/Primary Endodontic Lesion\"\n",
        "Pr_Pe_wi_En_SOURCE_DIR=\"/content/Periapical_Xrays/Primary Perio with Secondary Endo\"\n",
        "Pr_Pe_Le_SOURCE_DIR=\"/content/Periapical_Xrays/Primary Periodontal Lesion\"\n",
        "Tr_Co_Le_SOURCE_DIR=\"/content/Periapical_Xrays/True Combined Lesions\"\n",
        "\n",
        "TRAINING_DIR = \"/content/Xrays/training\"\n",
        "VALIDATION_DIR = \"/content/Xrays/validation\"\n",
        "\n",
        "TRAINING_Pr_En_wi_Se_Pe_DIR = os.path.join(TRAINING_DIR, \"Primary Endo with Secondary Perio/\")\n",
        "TRAINING_Pr_En_Le_DIR=os.path.join(TRAINING_DIR,\"Primary Endodontic Lesion/\")\n",
        "TRAINING_Pr_Pe_wi_En_DIR=os.path.join(TRAINING_DIR,\"Primary Perio with Secondary Endo/\")\n",
        "TRAINING_Pr_Pe_Le_DIR=os.path.join(TRAINING_DIR,\"Primary Periodontal Lesion/\")\n",
        "TRAINING_Tr_Co_Le_DIR=os.path.join(TRAINING_DIR,\"True Combined Lesions/\")\n",
        "\n",
        "\n",
        "VALIDATION_Pr_En_wi_Se_Pe_DIR = os.path.join(VALIDATION_DIR, \"Primary Endo with Secondary Perio/\")\n",
        "VALIDATION_Pr_En_Le_DIR=os.path.join(VALIDATION_DIR,\"Primary Endodontic Lesion/\")\n",
        "VALIDATION_Pr_Pe_wi_En_DIR=os.path.join(VALIDATION_DIR,\"Primary Perio with Secondary Endo/\")\n",
        "VALIDATION_Pr_Pe_Le_DIR=os.path.join(VALIDATION_DIR,\"Primary Periodontal Lesion/\")\n",
        "VALIDATION_Tr_Co_Le_DIR=os.path.join(VALIDATION_DIR,\"True Combined Lesions/\")\n",
        "\n",
        "\n",
        "# Define proportion of images used for training\n",
        "split_size = .85\n",
        "\n",
        "# Run the function\n",
        "# NOTE: Messages about zero length images should be printed out\n",
        "split_data(Pr_En_wi_Se_Pe_SOURCE_DIR, TRAINING_Pr_En_wi_Se_Pe_DIR,VALIDATION_Pr_En_wi_Se_Pe_DIR, split_size)\n",
        "split_data(Pr_En_Le_SOURCE_DIR, TRAINING_Pr_En_Le_DIR,VALIDATION_Pr_En_Le_DIR, split_size)\n",
        "split_data(Pr_Pe_wi_En_SOURCE_DIR,TRAINING_Pr_Pe_wi_En_DIR,VALIDATION_Pr_Pe_wi_En_DIR,split_size)\n",
        "split_data(Pr_Pe_Le_SOURCE_DIR,TRAINING_Pr_Pe_Le_DIR,VALIDATION_Pr_Pe_Le_DIR,split_size)\n",
        "split_data(Tr_Co_Le_SOURCE_DIR,TRAINING_Tr_Co_Le_DIR,VALIDATION_Tr_Co_Le_DIR,split_size)\n",
        "\n",
        "# Check that the number of images matches the expected output\n",
        "\n",
        "# Your function should perform copies rather than moving images so original directories should contain unchanged images\n",
        "print(f\"\\n\\nOriginal Primary Endo with Secondary Perio directory has {len(os.listdir(Pr_En_wi_Se_Pe_SOURCE_DIR))} images\")\n",
        "print(f\"Original Primary Endodontic Lesion directory has {len(os.listdir(Pr_En_Le_SOURCE_DIR))} images\\n\")\n",
        "print(f\"Orignal Primary Perio with Secondary Endo has {len(os.listdir(Pr_Pe_wi_En_SOURCE_DIR))} images\\n\")\n",
        "print(f\"Orignal Primary Periodontal Lesion has {len(os.listdir(Pr_Pe_Le_SOURCE_DIR))} images\\n\")\n",
        "print(f\"Orignal True Combined Lesions has {len(os.listdir(Tr_Co_Le_SOURCE_DIR))} images\\n\")\n",
        "\n",
        "# Training and validation splits\n",
        "print(f\"There are {len(os.listdir(TRAINING_Pr_En_wi_Se_Pe_DIR))} images of Primary Endo with Secondary Perio directory for training\")\n",
        "print(f\"There are {len(os.listdir(TRAINING_Pr_En_Le_DIR))} images of Primary Endodontic Lesion directory for training\")\n",
        "print(f\"There are {len(os.listdir(TRAINING_Pr_Pe_wi_En_DIR))} images of Primary Perio with Secondary Endo directory for training\")\n",
        "print(f\"There are {len(os.listdir(TRAINING_Pr_Pe_Le_DIR))} images of Primary Periodontal Lesion directory for training\")\n",
        "print(f\"There are {len(os.listdir(TRAINING_Tr_Co_Le_DIR))} images of True Combined Lesions directory for training\\n\")\n",
        "\n",
        "print(f\"There are {len(os.listdir(VALIDATION_Pr_En_wi_Se_Pe_DIR))} images of Primary Endo with Secondary Perio for validation\")\n",
        "print(f\"There are {len(os.listdir(VALIDATION_Pr_En_Le_DIR))} images of Primary Endodontic Lesion for validation\")\n",
        "print(f\"There are {len(os.listdir(VALIDATION_Pr_Pe_wi_En_DIR))} images of  Primary Perio with Secondary Endo for validation\")\n",
        "print(f\"There are {len(os.listdir(VALIDATION_Pr_Pe_Le_DIR))} images of  Primary Periodontal Lesion for validaton\")\n",
        "print(f\"There are {len(os.listdir(VALIDATION_Tr_Co_Le_DIR))} images of  True Combined Lesions for validation\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUyvNGORAdN5",
        "outputId": "032bbbf8-8d69-4e75-b717-54b414d4d142"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Original Primary Endo with Secondary Perio directory has 122 images\n",
            "Original Primary Endodontic Lesion directory has 124 images\n",
            "\n",
            "Orignal Primary Perio with Secondary Endo has 39 images\n",
            "\n",
            "Orignal Primary Periodontal Lesion has 118 images\n",
            "\n",
            "Orignal True Combined Lesions has 131 images\n",
            "\n",
            "There are 103 images of Primary Endo with Secondary Perio directory for training\n",
            "There are 105 images of Primary Endodontic Lesion directory for training\n",
            "There are 33 images of Primary Perio with Secondary Endo directory for training\n",
            "There are 100 images of Primary Periodontal Lesion directory for training\n",
            "There are 111 images of True Combined Lesions directory for training\n",
            "\n",
            "There are 19 images of Primary Endo with Secondary Perio for validation\n",
            "There are 19 images of Primary Endodontic Lesion for validation\n",
            "There are 6 images of  Primary Perio with Secondary Endo for validation\n",
            "There are 18 images of  Primary Periodontal Lesion for validaton\n",
            "There are 20 images of  True Combined Lesions for validation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read input images and assign labels based on folder names\n",
        "print(os.listdir(\"Xrays/\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWg29C8tQv_w",
        "outputId": "1b2a70d6-64ad-45bb-fe69-9f5741ff0c34"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['validation', 'training']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SIZE = 227  #Resize images"
      ],
      "metadata": {
        "id": "rF8fRmNMSD_F"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Capture training data and labels into respective lists\n",
        "train_images = []\n",
        "train_labels = []"
      ],
      "metadata": {
        "id": "HIjnvUkWZPIA"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for directory_path in glob.glob(\"/content/Xrays/training/*\"):\n",
        "    train_label = directory_path.split(\"/\")[-1]\n",
        "    print(train_label)\n",
        "    for img_path in glob.glob(os.path.join(directory_path, \"*.JPG\")):\n",
        "      print(img_path)\n",
        "      img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
        "      img = cv2.resize(img, (SIZE, SIZE))\n",
        "      img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "      train_images.append(img)\n",
        "      train_labels.append(train_label)"
      ],
      "metadata": {
        "id": "OJQpss-NZWtw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert lists to arrays\n",
        "train_images = np.array(train_images)\n",
        "train_labels = np.array(train_labels)"
      ],
      "metadata": {
        "id": "q-ABYijIGstC"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Capture test/validation data and labels into respective lists\n",
        "\n",
        "test_images = []\n",
        "test_labels = []\n",
        "for directory_path in glob.glob(\"/content/Xrays/validation/*\"):\n",
        "    label = directory_path.split(\"/\")[-1]\n",
        "    # print(label)\n",
        "\n",
        "    for img_path in glob.glob(os.path.join(directory_path, \"*.JPG\")):\n",
        "\n",
        "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
        "        img = cv2.resize(img, (SIZE, SIZE))\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "        test_images.append(img)\n",
        "        test_labels.append(label)"
      ],
      "metadata": {
        "id": "jSAsmqrZHVWh"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert lists to arrays\n",
        "test_images = np.array(test_images)\n",
        "test_labels = np.array(test_labels)"
      ],
      "metadata": {
        "id": "0CqR5jfcH2BC"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_images.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEU-1kAnH4Zh",
        "outputId": "785b417f-f50f-4f83-9d0a-4ec4c03d5eff"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(82, 227, 227, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKRQBKhaJwby",
        "outputId": "428ae16e-3d2d-4517-9ca6-54ed98677a6a"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(82,)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Encode labels from text to integers.\n",
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(test_labels)\n",
        "test_labels_encoded = le.transform(test_labels)\n",
        "le.fit(train_labels)\n",
        "train_labels_encoded = le.transform(train_labels)"
      ],
      "metadata": {
        "id": "IZ9eQbfOJylx"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize pixel values to between 0 and 1\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0"
      ],
      "metadata": {
        "id": "Ba7_-S2aKNHv"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#One hot encode y values for neural network.\n",
        "from keras.utils import to_categorical\n",
        "y_train_one_hot = to_categorical(train_labels_encoded)\n",
        "y_test_one_hot = to_categorical(test_labels_encoded)"
      ],
      "metadata": {
        "id": "UKxoR6Y0KmUB"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load model wothout classifier/fully connected layers\n",
        "VGG_model = VGG16(weights='imagenet', include_top=False, input_shape=(SIZE, SIZE, 3))"
      ],
      "metadata": {
        "id": "lHvnKkNBLODQ"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Make loaded layers as non-trainable. This is important as we want to work with pre-trained weights\n",
        "for layer in VGG_model.layers:\n",
        "\tlayer.trainable = False"
      ],
      "metadata": {
        "id": "yy1TIQUuMBeB"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VGG_model.summary()  #Trainable parameters will be 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyF0NGY4MFAx",
        "outputId": "af7bdb08-205e-4b1e-dc49-f86813a849c1"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 227, 227, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 227, 227, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 227, 227, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 113, 113, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 113, 113, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 113, 113, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 0\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Now, let us use features from convolutional network for RF\n",
        "feature_extractor=VGG_model.predict(train_images)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0l6ZGAhMHmg",
        "outputId": "c7dc9954-2465-465d-8234-7ce30649795c"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 289s 19s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_extractor.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKCmHqzKP9Lu",
        "outputId": "a6acbde9-582e-457f-887a-b2b0b9bb3fb7"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(452, 7, 7, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features = feature_extractor.reshape(feature_extractor.shape[0], -1)"
      ],
      "metadata": {
        "id": "6pwxpqBZRuAQ"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-le6PjwR4My",
        "outputId": "032082bf-c088-49c5-f682-b23ad1f28edf"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(452, 25088)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_for_SVM = features #This is our X input to SV"
      ],
      "metadata": {
        "id": "jEooM0p0R6Ih"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "mI3ajo7MS6Jb"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an SVM classifier with the OvR strategy\n",
        "SVM_Classifier = SVC(kernel=\"linear\")"
      ],
      "metadata": {
        "id": "pshSCXxzS8ix"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model on the training data and labels\n",
        "\n",
        "SVM_Classifier.fit(X_for_SVM , train_labels_encoded)#For sklearn no one hot encoding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "tAmnW7eXUD-S",
        "outputId": "14c1c8d5-076a-4574-c554-83edb4597fb7"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(kernel='linear')"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Send test data through same feature extractor process\n",
        "X_test_feature = VGG_model.predict(test_images)\n",
        "X_test_features = X_test_feature.reshape(X_test_feature.shape[0], -1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYjaqwnWU_qx",
        "outputId": "987b8e06-b670-42eb-cad8-b9ec9832696a"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 52s 16s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using the model to predict the labels of the test data\n",
        "prediction_SVM = SVM_Classifier.predict(X_test_features)\n",
        "\n"
      ],
      "metadata": {
        "id": "SSomq4dGWwoe"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Inverse le transform to get original label back.\n",
        "prediction_SVM = le.inverse_transform(prediction_SVM)"
      ],
      "metadata": {
        "id": "eNmFe9ktXsTA"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(test_labels, prediction_SVM)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "nFUchmITYXOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VuwbtQXhYzRR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}